{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f4833f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/Users/rv/Projects/7CS074') # Change to the project root directory\n",
    "\n",
    "# Now we can import the modules\n",
    "import src.preprocessing as preprocessing\n",
    "import src.visualisation as visualisation\n",
    "\n",
    "import src.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b05130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we will check and run the preprocessing script\n",
    "# In case this is already done, this will not overwrite existing files\n",
    "preprocessing.process_raw_multiple_data_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30d45b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "if not os.path.exists(preprocessing.DATASET_CLEAN_FILE_PATH):\n",
    "    raise FileNotFoundError(f\"Dataset not found at {preprocessing.DATASET_CLEAN_FILE_PATH}. Please ensure the dataset is placed correctly.\")\n",
    "\n",
    "df = pd.read_csv(preprocessing.DATASET_CLEAN_FILE_PATH, sep=',', engine='python') # read with proper delimiter handling, and with python engine always\n",
    "if df.empty:\n",
    "    raise ValueError(\"Loaded dataset is empty. Please check the dataset file.\")\n",
    "\n",
    "print(f\"Data loaded successfully from {preprocessing.DATASET_CLEAN_FILE_PATH}.\")\n",
    "\n",
    "# We will use the first 10 columns as features\n",
    "# However we need to slice the 'price' column correctly, which is at index 3\n",
    "feature_cols = ['year', 'mileage', 'tax', 'mpg', 'engineSize']\n",
    "target_col = 'price'\n",
    "\n",
    "# # One-hot encode categorical variables for better model performance\n",
    "# categorical_cols = ['make', 'model', 'transmission', 'fuelType']\n",
    "# df = pd.get_dummies(df, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "all_models, trained_models_per_make = models.automatic_make_model_selection(\n",
    "    df,\n",
    "    feature_cols,\n",
    "    target_col,\n",
    "    min_samples_per_make=300\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfe221f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation import regression_metrics\n",
    "\n",
    "for make_vehicle, data in all_models.items():\n",
    "\tmetrics = data['metrics']\n",
    "\tprint(f\"Make: {make_vehicle}, MAE: {metrics['MAE']}, RMSE: {metrics['RMSE']}, R2: {metrics['R2']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0575f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for make_vehicle, algorithm_data in trained_models_per_make.items():\n",
    "\tmodel = algorithm_data['model']\n",
    "\tY_test = algorithm_data['y_test']\n",
    "\tX_test = algorithm_data['X_test']\n",
    "\n",
    "\tpredictions = algorithm_data['predictions']\n",
    "\tmetrics = algorithm_data['metrics']\n",
    " \n",
    "\tvisualisation.plot_feature_importances(model, feature_cols, f'Random Forest Regressor Feature Importances - For {make_vehicle}')\n",
    "\tvisualisation.plot_actual_vs_predicted(Y_test, predictions, f'Random Forest Regressor - For {make_vehicle}', metrics['R2'])\n",
    "\tvisualisation.plot_price_vs_mpg(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
